{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data in right format and remove unfitted samples\n",
    "get data in our format (REDO, some labels are empty remove these, readline = nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../image_data/norwegian_data/all.csv', 'w') as f:\n",
    "#     f.write('Image,Word\\n') \n",
    "\n",
    "# for file in tqdm(os.listdir('../image_data/norwegian')):\n",
    "#     if file[-4:] == '.jpg':\n",
    "#         image = file\n",
    "\n",
    "#         shutil.copy(f'../image_data/norwegian/{file}', f'../image_data/norwegian_data/all/{file}')\n",
    "\n",
    "#         with open(f'../image_data/norwegian/{file[:-4]}.txt', 'r') as f:\n",
    "#             word = f.readline()\n",
    "\n",
    "#         with open('../image_data/norwegian_data/all.csv', 'a') as f:\n",
    "#             f.write(f'{image},{word}\\n') \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sort out samples that can fit the phosc framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_word(word) -> bool:\n",
    "#     # try captures if the word is not a string, like nan\n",
    "#     valid_characters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'æ', 'ø', 'å']\n",
    "#     valid_characters_upper = [char.upper() for char in valid_characters]\n",
    "    \n",
    "#     try:\n",
    "#         for ch in word:\n",
    "#             if (not ch.isalpha()):\n",
    "#                 return False\n",
    "#             elif ch not in valid_characters:\n",
    "#                 if ch not in valid_characters_upper:\n",
    "#                     return False\n",
    "#     except TypeError:\n",
    "#         return False\n",
    "\n",
    "#     return True\n",
    "\n",
    "# df = pd.read_csv('../image_data/norwegian_data/all.csv', on_bad_lines='skip')\n",
    "\n",
    "# with open(f'../image_data/norwegian_data/trim.csv', 'w') as f:\n",
    "#     f.write('Image,Word\\n')\n",
    "\n",
    "# os.makedirs('../image_data/norwegian_data/trim')\n",
    "\n",
    "# for i in tqdm(range(len(df))):\n",
    "\n",
    "#     if is_word(df.iloc[i, 1]):\n",
    "#         with open(f'../image_data/norwegian_data/trim.csv', 'a') as f:\n",
    "#             f.write(f'{df.iloc[i, 0]},{df.iloc[i, 1]}\\n')\n",
    "#         shutil.copy(f'../image_data/norwegian_data/all/{df.iloc[i, 0]}', f'../image_data/norwegian_data/trim/{df.iloc[i, 0]}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes 9118\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../image_data/norwegian_data/trim.csv')\n",
    "\n",
    "word_dict = {}\n",
    "\n",
    "for word in df.iloc[:, 1]:\n",
    "    if not word in word_dict.keys():\n",
    "        word_dict[word] = 1\n",
    "    else:\n",
    "        word_dict[word] += 1\n",
    "\n",
    "print('classes', len(word_dict.keys()))\n",
    "# print(word_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "presence of æøå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'æ': 745, 'ø': 693, 'å': 255, 'Æ': 4, 'Ø': 14, 'Å': 4}\n"
     ]
    }
   ],
   "source": [
    "def word_contains_æøå(word):\n",
    "    word = word.lower()\n",
    "    if 'æ' in word or 'ø' in word or 'å':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "æøå_dict = {'æ': 0, 'ø': 0, 'å': 0, 'Æ': 0, 'Ø': 0, 'Å': 0}\n",
    "\n",
    "for word in word_dict.keys():\n",
    "    if word_contains_æøå(word):\n",
    "        for key in æøå_dict.keys():\n",
    "            if key in word:\n",
    "                æøå_dict[key] += 1\n",
    "\n",
    "print(æøå_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most common bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ss': 1, 'dd': 1, 'uu': 1, 'wo': 1, 'bt': 1, 'gæ': 1, 'ax': 1, 'zi': 1, 'py': 1, 'dj': 1, 'ze': 1, 'gn': 1, 'kh': 1, 'dv': 1, 'qv': 1, 'ic': 1, 'td': 1, 'lg': 1, 'ee': 1, 'øl': 1, 'sh': 1, 'yr': 1, 'yl': 1, 'zw': 1, 'cu': 1, 'pæ': 1, 'ng': 1, 'oe': 1, 'bh': 1, 'øc': 1, 'bn': 1, 'gs': 1, 'æk': 1, 'mc': 1, 'kt': 1, 'rt': 1, 'rr': 1, 'mn': 1, 'zo': 1, 'jg': 1, 'wa': 1, 'ea': 1, 'ts': 1, 'øy': 1, 'øm': 1, 'kå': 1, 'mj': 1, 'dp': 1, 'ås': 1, 'jø': 1, 'gv': 1, 'hl': 1, 'nt': 1, 'tp': 1, 'uo': 1, 'tt': 1, 'yo': 1, 'gt': 1, 'ae': 1, 'ok': 2, 'ej': 2, 'ir': 2, 'øk': 2, 'ji': 2, 'ec': 2, 'rh': 2, 'dl': 2, 'ør': 2, 'æs': 2, 'uc': 2, 'æt': 2, 'æn': 2, 'ui': 2, 'ii': 2, 'då': 2, 'ib': 2, 'up': 3, 'vu': 3, 'øe': 3, 'oo': 3, 'za': 3, 'oi': 3, 'ph': 3, 'ce': 3, 'ot': 3, 'åp': 3, 'kø': 4, 'dæ': 4, 'tå': 4, 'ån': 4, 'ød': 4, 'ob': 4, 'jæ': 4, 'yt': 5, 'ep': 5, 'qu': 5, 'ps': 5, 'ih': 5, 'es': 5, 'yp': 6, 'eu': 7, 'øj': 7, 'lå': 7, 'ue': 7, 'uh': 7, 'ek': 7, 'ky': 7, 'ac': 7, 'as': 8, 'øs': 8, 'au': 8, 'æl': 8, 'tj': 8, 'it': 8, 'ci': 9, 'ab': 9, 'cl': 9, 'gy': 9, 'eb': 9, 'wi': 9, 'vå': 10, 'my': 10, 'ol': 10, 'uk': 10, 'em': 11, 'if': 11, 'um': 11, 'ry': 11, 'bæ': 11, 'åb': 12, 'ub': 12, 'uv': 12, 'æg': 12, 'ev': 12, 'sj': 12, 'sc': 13, 'ca': 13, 'ua': 13, 'øv': 14, 'ræ': 14, 'yd': 14, 'vr': 14, 'fy': 14, 'co': 14, 'hr': 14, 'ug': 15, 'ap': 15, 'iv': 15, 'am': 15, 'gø': 16, 'rå': 16, 'yn': 16, 'on': 17, 'us': 17, 'il': 17, 'ur': 18, 'kn': 18, 'pi': 19, 'ni': 19, 'ch': 19, 'ak': 19, 'ul': 19, 'uf': 20, 'bj': 21, 'ag': 21, 'pu': 21, 'we': 21, 'kæ': 22, 'hy': 23, 'hæ': 24, 'ru': 24, 'ia': 24, 'fj': 24, 'tv': 25, 'bå': 25, 'mæ': 25, 'ex': 26, 'dø': 27, 'ke': 28, 'ki': 28, 'tø': 28, 'su': 28, 'ju': 29, 'dy': 29, 'rø': 29, 'lu': 29, 'ær': 31, 'år': 31, 'nø': 31, 'ad': 31, 'hå': 34, 'ei': 34, 'is': 35, 'kv': 35, 'øi': 35, 'øn': 36, 'ty': 37, 'ra': 37, 'mø': 37, 'ed': 38, 'ig': 39, 'of': 39, 'po': 40, 'bu': 40, 'fe': 43, 'ro': 43, 'tu': 44, 'fæ': 45, 'gu': 46, 'fl': 47, 'lø': 47, 'by': 47, 'th': 48, 'id': 48, 'nå': 48, 'bø': 50, 'pl': 51, 'im': 54, 'gå': 55, 'mu': 59, 'ge': 62, 'eg': 62, 'lo': 63, 'sæ': 63, 'ja': 63, 'kl': 64, 'aa': 64, 'te': 65, 'tæ': 68, 'sn': 68, 'os': 69, 'dr': 70, 'or': 72, 'sm': 72, 'bi': 75, 'ly': 76, 'fu': 81, 'ny': 82, 'få': 83, 'ut': 90, 'gl': 92, 'sy': 98, 'sl': 100, 'do': 101, 'sv': 101, 'gi': 101, 'sø': 101, 'pe': 102, 'fi': 107, 'sp': 108, 'pr': 110, 'ar': 112, 'ri': 113, 'bo': 115, 'to': 116, 'kr': 117, 'læ': 118, 'må': 119, 'næ': 120, 'vo': 123, 'gr': 124, 'go': 133, 'hø': 138, 'ef': 141, 'hj': 144, 'jo': 150, 'un': 153, 'hi': 156, 'ne': 161, 'le': 166, 'av': 168, 'br': 182, 'ba': 182, 'la': 189, 'mo': 198, 'na': 200, 'ho': 204, 'fø': 205, 'så': 206, 'kj': 217, 'el': 222, 'tr': 234, 'gj': 237, 'nu': 239, 'på': 244, 'ov': 246, 'op': 249, 'ud': 254, 're': 256, 'ta': 261, 'hu': 273, 'ga': 283, 'ka': 284, 'ku': 286, 'fa': 293, 'væ': 311, 'an': 328, 'ko': 352, 'no': 354, 'du': 360, 'in': 363, 'bl': 368, 'li': 383, 'da': 387, 'di': 404, 'se': 406, 'et': 436, 'pa': 446, 'om': 455, 've': 475, 'va': 483, 'fr': 493, 'al': 508, 'hv': 510, 'be': 519, 'ma': 532, 'st': 570, 'sk': 579, 'af': 584, 'ik': 603, 'si': 634, 'he': 656, 'sa': 662, 'so': 689, 'vi': 862, 'mi': 890, 'er': 926, 'ti': 1143, 'en': 1159, 'fo': 1279, 'me': 1345, 'at': 1455, 'je': 1515, 'ha': 1768, 'og': 1828, 'de': 3407}\n",
      "336\n",
      "\n",
      "de 3407\n",
      "og 1828\n",
      "ha 1768\n",
      "je 1515\n",
      "at 1455\n",
      "me 1345\n",
      "fo 1279\n",
      "en 1159\n",
      "ti 1143\n",
      "er 926\n",
      "mi 890\n",
      "vi 862\n",
      "so 689\n",
      "sa 662\n",
      "he 656\n",
      "si 634\n",
      "ik 603\n",
      "af 584\n",
      "sk 579\n",
      "st 570\n",
      "ma 532\n",
      "be 519\n",
      "hv 510\n",
      "al 508\n",
      "fr 493\n",
      "va 483\n",
      "ve 475\n",
      "om 455\n",
      "pa 446\n",
      "et 436\n",
      "se 406\n",
      "di 404\n",
      "da 387\n",
      "li 383\n",
      "bl 368\n",
      "in 363\n",
      "du 360\n",
      "no 354\n",
      "ko 352\n",
      "an 328\n",
      "væ 311\n",
      "fa 293\n",
      "ku 286\n",
      "ka 284\n",
      "ga 283\n",
      "hu 273\n",
      "ta 261\n",
      "re 256\n",
      "ud 254\n",
      "op 249\n",
      "['de', 'og', 'ha', 'je', 'at', 'me', 'fo', 'en', 'ti', 'er', 'mi', 'vi', 'so', 'sa', 'he', 'si', 'ik', 'af', 'sk', 'st', 'ma', 'be', 'hv', 'al', 'fr', 'va', 've', 'om', 'pa', 'et', 'se', 'di', 'da', 'li', 'bl', 'in', 'du', 'no', 'ko', 'an', 'væ', 'fa', 'ku', 'ka', 'ga', 'hu', 'ta', 're', 'ud', 'op']\n"
     ]
    }
   ],
   "source": [
    "bigram_dict = {}\n",
    "\n",
    "for word in word_dict.keys():\n",
    "    op_word = word.lower()\n",
    "\n",
    "    if len(word) < 2:\n",
    "        continue\n",
    "\n",
    "    if not op_word[0:2] in bigram_dict.keys():\n",
    "        bigram_dict[op_word[0:2]] = word_dict[word]\n",
    "    else:\n",
    "        bigram_dict[op_word[0:2]] += word_dict[word]\n",
    "\n",
    "bigram_dict = {k: v for k, v in sorted(bigram_dict.items(), key=lambda item: item[1])}\n",
    "print(bigram_dict)\n",
    "print(len(bigram_dict))\n",
    "print()\n",
    "\n",
    "for bigram in list(bigram_dict.keys())[-1: -51: -1]:\n",
    "    print(bigram, bigram_dict[bigram])\n",
    "\n",
    "print(list(bigram_dict.keys())[-1: -51: -1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7585dd4ff129a3d41bb6c9e690265866f8901fe8c84f068f677d959cb33c37c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
